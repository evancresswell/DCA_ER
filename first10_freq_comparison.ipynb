{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840ba38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import Bio.PDB, warnings\n",
    "pdb_list = Bio.PDB.PDBList()\n",
    "pdb_parser = Bio.PDB.PDBParser()\n",
    "from scipy.spatial import distance_matrix\n",
    "from Bio import BiopythonWarning\n",
    "warnings.simplefilter('ignore', BiopythonWarning)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import timeit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# # --- Import our Code ---# #\n",
    "#import emachine as EM\n",
    "from direct_info import direct_info\n",
    "\n",
    "# import data processing and general DCA_ER tools\n",
    "from data_processing import data_processing\n",
    "import ecc_tools as tools\n",
    "from pathlib import Path\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4d9e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pdb structures: 372\n",
      "        PF seq            id uniprot_start uniprot_end pdb_id chain pdb_start  \\\n",
      "0  PF00186  69  Q5KZ26_GEOKA             1         160   1ZDR     B         1   \n",
      "1  PF00186  69  Q5KZ26_GEOKA             1         160   1ZDR     A         1   \n",
      "2  PF00186  83  Q81R22_BACAN             2         160   3JWK     B         2   \n",
      "3  PF00186  83  Q81R22_BACAN             2         160   3S9U     B         2   \n",
      "4  PF00186  83  Q81R22_BACAN             2         160   3FL9     H         2   \n",
      "\n",
      "  pdb_end  \n",
      "0     160  \n",
      "1     160  \n",
      "2     160  \n",
      "3     160  \n",
      "4     160  \n"
     ]
    }
   ],
   "source": [
    "data_path = Path('/home', 'eclay','Pfam-A.full')\n",
    "data_path = Path('Pfam-A.full')\n",
    "DCA_ER_dir = Path('/home/evan/PycharmProjects/DCA_ER/')\n",
    "\n",
    "\n",
    "\n",
    "pfam_id = 'PF00023'\n",
    "pfam_id = 'PF00011'\n",
    "pfam_id = 'PF00186'\n",
    "\n",
    "n_jobs = 26\n",
    "create_new = True\n",
    "computing_pydca_mf = False\n",
    "\n",
    "\n",
    "if 0:\n",
    "    DCA_ER_dir = '/home/eclay/DCA_ER/'\n",
    "    msa_npy_file = '/home/eclay/Pfam-A.full/%s/msa.npy' % pfam_id # Hurricane Location\n",
    "    msa_fa_file  = '/home/eclay/Pfam-A.full/%s/msa.fa' % pfam_id # Hurricane Location\n",
    "    pdb_ref_file = '/home/eclay/Pfam-A.full/%s/pdb_refs.npy' % pfam_id # Hurricane Location\n",
    "if 1:\n",
    "    DCA_ER_dir = '/home/evan/DCA_ER/'\n",
    "    msa_npy_file = '/home/evan/DCA_ER/Pfam-A.full/%s/msa.npy' % pfam_id\n",
    "    msa_fa_file  = '/home/evan/DCA_ER/Pfam-A.full/%s/msa.fa' % pfam_id\n",
    "    pdb_ref_file = '/home/evan/DCA_ER/Pfam-A.full/%s/pdb_refs.npy' % pfam_id\n",
    "    out_dir = '%sprotein_data/di/' % DCA_ER_dir\n",
    "if 0:\n",
    "    DCA_ER_dir = '/home/ecresswell/DCA_ER/'\n",
    "    msa_npy_file = '/home/ecresswell/DCA_ER/Pfam-A.full/%s/msa.npy' % pfam_id\n",
    "    msa_fa_file  = '/home/ecresswell/DCA_ER/Pfam-A.full/%s/msa.fa' % pfam_id\n",
    "    pdb_ref_file = '/home/ecresswell/DCA_ER/Pfam-A.full/%s/pdb_refs.npy' % pfam_id\n",
    "    out_dir = '%sprotein_data/di/' % DCA_ER_dir\n",
    "if 0:\n",
    "    DCA_ER_dir = '/data/cresswellclayec/DCA_ER/'\n",
    "    msa_npy_file = '/data/cresswellclayec/DCA_ER/Pfam-A.full/%s/msa.npy' % pfam_id\n",
    "    msa_fa_file  = '/data/cresswellclayec/DCA_ER/Pfam-A.full/%s/msa.fa' % pfam_id\n",
    "    pdb_ref_file = '/data/cresswellclayec/DCA_ER/Pfam-A.full/%s/pdb_refs.npy' % pfam_id\n",
    "    out_dir = '%sprotein_data/di/' % DCA_ER_dir\n",
    "if 1:\n",
    "    DCA_ER_dir = '/home/evan/PycharmProjects/DCA_ER/'\n",
    "    msa_npy_file = '/home/evan/PycharmProjects/DCA_ER/Pfam-A.full/%s/msa.npy' % pfam_id\n",
    "    msa_fa_file  = '/home/evan/PycharmProjects/DCA_ER/Pfam-A.full/%s/msa.fa' % pfam_id\n",
    "    pdb_ref_file = '/home/evan/PycharmProjects/DCA_ER/Pfam-A.full/%s/pdb_refs.npy' % pfam_id\n",
    "    out_dir = '%sprotein_data/di/' % DCA_ER_dir\n",
    "\n",
    "\n",
    "\n",
    "# Set DCA_ER directory\n",
    "DCA_dir = os.getcwd()\n",
    "\n",
    "# Define data directories\n",
    "# Need to think on best way to do this..\n",
    "# Referencing the same dataframe may be useful so we dont always have to load individual ref files...\n",
    "individual_pdb_ref_file = Path(data_path, pfam_id, 'pdb_refs.npy')\n",
    "pdb = np.load(individual_pdb_ref_file)\n",
    "processed_data_dir = \"%s/protein_data/data_processing_output\" % DCA_dir\n",
    "\n",
    "# delete 'b' in front of letters (python 2 --> python 3)\n",
    "pdb = np.array([pdb[t,i].decode('UTF-8') for t in range(pdb.shape[0]) \\\n",
    "         for i in range(pdb.shape[1])]).reshape(pdb.shape[0],pdb.shape[1])\n",
    "\n",
    "\n",
    "# Print number of pdb structures in Protein ID folder\n",
    "npdb = pdb.shape[0]\n",
    "print('number of pdb structures:',npdb)\n",
    "\n",
    "# Create pandas dataframe for protein structure\n",
    "pdb_df = pd.DataFrame(pdb,columns = ['PF','seq','id','uniprot_start','uniprot_end',\\\n",
    "                                 'pdb_id','chain','pdb_start','pdb_end'])\n",
    "print(pdb_df.head())\n",
    "\n",
    "# print(\"Direct Information from Expectation reflection:\\n\",di)\n",
    "def no_diag(mat, diag_l, s_index=None, make_big=False):\n",
    "    rows, columns = mat.shape\n",
    "    if make_big:\n",
    "        new_mat = 100. * np.ones((rows,columns))\n",
    "    else:\n",
    "        new_mat = np.zeros((rows,columns))\n",
    "    for row in range(rows):\n",
    "        for col in range(columns):\n",
    "            if s_index is None:\n",
    "                if abs(row-col) > diag_l:\n",
    "                    new_mat[row, col] = mat[row ,col]\n",
    "            else:\n",
    "                if abs(s_index[row]-s_index[col]) > diag_l:\n",
    "                    new_mat[row, col] = mat[row ,col]    \n",
    "    return new_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6b5429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq: 69\n",
      "pdb ref example (pdb[0])  (after UTF-8 decode, removing 'b'):\n",
      " ['PF00186' '69' 'Q5KZ26_GEOKA' '1' '160' '1ZDR' 'B' '1' '160']\n",
      "tpdb (s_ipdb) is :  69\n",
      "#\n",
      "\n",
      "-------------------------Remove Gaps--------------------------#\n",
      "Shape of s is :  (7750, 918)\n",
      "s = \n",
      " [['-' '-' '-' ... '-' '-' '-']\n",
      " ['-' '-' '-' ... '-' '-' '-']\n",
      " ['-' '-' '-' ... '-' '-' '-']\n",
      " ...\n",
      " ['-' '-' '-' ... '-' '-' '-']\n",
      " ['-' '-' '-' ... '-' '-' '-']\n",
      " ['-' '-' '-' ... '-' '-' '-']]\n",
      "s[tpdb] shape is  (160,)\n",
      "s = \n",
      " [['-' '-' '-' ... 'Y' 'E' 'K']\n",
      " ['M' 'I' 'S' ... 'W' 'E' 'R']\n",
      " ['-' 'L' 'A' ... 'Y' 'E' 'R']\n",
      " ...\n",
      " ['-' '-' '-' ... '-' '-' '-']\n",
      " ['-' 'V' 'S' ... 'Y' 'E' 'R']\n",
      " ['-' 'F' 'S' ... 'Y' 'E' 'K']]\n",
      "though s still has gaps, s[69] does not:\n",
      " ['M' 'I' 'S' 'H' 'I' 'V' 'A' 'M' 'D' 'E' 'N' 'R' 'V' 'I' 'G' 'K' 'D' 'N'\n",
      " 'R' 'L' 'P' 'W' 'H' 'L' 'P' 'A' 'D' 'L' 'A' 'Y' 'F' 'K' 'R' 'V' 'T' 'M'\n",
      " 'G' 'H' 'A' 'I' 'V' 'M' 'G' 'R' 'K' 'T' 'F' 'E' 'A' 'I' 'G' 'R' 'P' 'L'\n",
      " 'P' 'G' 'R' 'D' 'N' 'V' 'V' 'V' 'T' 'R' 'N' 'R' 'S' 'F' 'R' 'P' 'E' 'G'\n",
      " 'C' 'L' 'V' 'L' 'H' 'S' 'L' 'E' 'E' 'V' 'K' 'Q' 'W' 'I' 'A' 'S' 'R' 'A'\n",
      " 'D' 'E' 'V' 'F' 'I' 'I' 'G' 'G' 'A' 'E' 'L' 'F' 'R' 'A' 'T' 'M' 'P' 'I'\n",
      " 'V' 'D' 'R' 'L' 'Y' 'V' 'T' 'K' 'I' 'F' 'A' 'S' 'F' 'P' 'G' 'D' 'T' 'F'\n",
      " 'Y' 'P' 'P' 'I' 'S' 'D' 'D' 'E' 'W' 'E' 'I' 'V' 'S' 'Y' 'T' 'P' 'G' 'G'\n",
      " 'K' 'D' 'E' 'K' 'N' 'P' 'Y' 'E' 'H' 'A' 'F' 'I' 'I' 'Y' 'E' 'R']\n",
      "s shape is  (7750, 160)\n",
      "Saving indices of reference sequence s[69](length=160):\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159]\n",
      "#--------------------------------------------------------------#\n",
      "\n",
      "\n",
      "removing non aligned (lower case) columns in subject sequence:\n",
      "  [] \n",
      "\n",
      "found and removed 205 duplicates!\n",
      "After removing bad sequences, tpdb is now  68\n",
      "(7545, 160)\n",
      "In Data Processing Reference Sequence (shape= (160,) ): \n",
      " ['M' 'I' 'S' 'H' 'I' 'V' 'A' 'M' 'D' 'E' 'N' 'R' 'V' 'I' 'G' 'K' 'D' 'N'\n",
      " 'R' 'L' 'P' 'W' 'H' 'L' 'P' 'A' 'D' 'L' 'A' 'Y' 'F' 'K' 'R' 'V' 'T' 'M'\n",
      " 'G' 'H' 'A' 'I' 'V' 'M' 'G' 'R' 'K' 'T' 'F' 'E' 'A' 'I' 'G' 'R' 'P' 'L'\n",
      " 'P' 'G' 'R' 'D' 'N' 'V' 'V' 'V' 'T' 'R' 'N' 'R' 'S' 'F' 'R' 'P' 'E' 'G'\n",
      " 'C' 'L' 'V' 'L' 'H' 'S' 'L' 'E' 'E' 'V' 'K' 'Q' 'W' 'I' 'A' 'S' 'R' 'A'\n",
      " 'D' 'E' 'V' 'F' 'I' 'I' 'G' 'G' 'A' 'E' 'L' 'F' 'R' 'A' 'T' 'M' 'P' 'I'\n",
      " 'V' 'D' 'R' 'L' 'Y' 'V' 'T' 'K' 'I' 'F' 'A' 'S' 'F' 'P' 'G' 'D' 'T' 'F'\n",
      " 'Y' 'P' 'P' 'I' 'S' 'D' 'D' 'E' 'W' 'E' 'I' 'V' 'S' 'Y' 'T' 'P' 'G' 'G'\n",
      " 'K' 'D' 'E' 'K' 'N' 'P' 'Y' 'E' 'H' 'A' 'F' 'I' 'I' 'Y' 'E' 'R']\n",
      "972\n",
      "After removing bad sequences, tpdb is now  55\n",
      "\n",
      "After removing bad sequences...\n",
      "tpdb (s_ipdb) is :  55\n",
      "(6573, 160)\n",
      "found bad columns := [  0  89 144 145 158 159]\n",
      "found conserved columns (80% repetition):\n",
      " [  6  13  14  21  30  34  41  42  43  45  53  56  96  97 114 123 127]\n",
      "We remove conserved and bad columns with, at the following indices:\n",
      " [  0   6  13  14 144 145  21  89  30 158 159  96  34  97  41  42  43  45\n",
      " 114  53  56 123 127]\n",
      "Removed Columns...\n",
      "s now has shape:  (6573, 137)\n",
      "s_index (length=137) = \n",
      " [  1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  19  20  22\n",
      "  23  24  25  26  27  28  29  31  32  33  35  36  37  38  39  40  44  46\n",
      "  47  48  49  50  51  52  54  55  57  58  59  60  61  62  63  64  65  66\n",
      "  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84\n",
      "  85  86  87  88  90  91  92  93  94  95  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 115 116 117 118 119 120 121 122 124 125\n",
      " 126 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 146\n",
      " 147 148 149 150 151 152 153 154 155 156 157]\n",
      "In Data Processing Reference Sequence (shape= (137,) ): \n",
      " ['I' 'S' 'H' 'I' 'V' 'M' 'D' 'E' 'N' 'R' 'V' 'K' 'D' 'N' 'R' 'L' 'P' 'H'\n",
      " 'L' 'P' 'A' 'D' 'L' 'A' 'Y' 'K' 'R' 'V' 'M' 'G' 'H' 'A' 'I' 'V' 'K' 'F'\n",
      " 'E' 'A' 'I' 'G' 'R' 'P' 'P' 'G' 'D' 'N' 'V' 'V' 'V' 'T' 'R' 'N' 'R' 'S'\n",
      " 'F' 'R' 'P' 'E' 'G' 'C' 'L' 'V' 'L' 'H' 'S' 'L' 'E' 'E' 'V' 'K' 'Q' 'W'\n",
      " 'I' 'A' 'S' 'R' 'D' 'E' 'V' 'F' 'I' 'I' 'A' 'E' 'L' 'F' 'R' 'A' 'T' 'M'\n",
      " 'P' 'I' 'V' 'D' 'R' 'L' 'Y' 'V' 'K' 'I' 'F' 'A' 'S' 'F' 'P' 'G' 'T' 'F'\n",
      " 'Y' 'P' 'I' 'S' 'D' 'D' 'E' 'W' 'E' 'I' 'V' 'S' 'Y' 'T' 'P' 'G' 'G' 'E'\n",
      " 'K' 'N' 'P' 'Y' 'E' 'H' 'A' 'F' 'I' 'I' 'Y']\n",
      "\n",
      "\n",
      "\n",
      "Preprocessed reference Sequence:  [ 7 15  6  7 17 10  2  3 11 14 17  8  2 11 14  9 12  6  9 12  0  2  9  0\n",
      " 19  8 14 17 10  5  6  0  7 17  8  4  3  0  7  5 14 12 12  5  2 11 17 17\n",
      " 17 16 14 11 14 15  4 14 12  3  5  1  9 17  9  6 15  9  3  3 17  8 13 18\n",
      "  7  0 15 14  2  3 17  4  7  7  0  3  9  4 14  0 16 10 12  7 17  2 14  9\n",
      " 19 17  8  7  4  0 15  4 12  5 16  4 19 12  7 15  2  2  3 18  3  7 17 15\n",
      " 19 16 12  5  5  3  8 11 12 19  3  6  0  4  7  7 19]\n",
      "After removing bad sequences, tpdb is now  68\n",
      "972\n",
      "After removing bad sequences, tpdb is now  55\n",
      "s after data_processing:  (6573, 160)\n",
      "Reference sequence (tpdb, s_ipdb) is sequence # 55\n",
      "shape of s \n",
      "import from /home/evan/PycharmProjects/DCA_ER/Pfam-A.full/PF00186/msa.npy\n",
      " (6573, 160)\n",
      "/home/evan/PycharmProjects/DCA_ER/Pfam-A.full/PF00186\n",
      "\n",
      "\n",
      "first 50 S:  (6573, 160) \n",
      "\n",
      "\n",
      "    PDB CHAIN  PDB_START  PDB_END PFAM_ACCESSION       PFAM_NAME  \\\n",
      "0  101m     A          7      113        PF00042          Globin   \n",
      "1  102l     A         24      149        PF00959  Phage_lysozyme   \n",
      "2  102m     A          7      113        PF00042          Globin   \n",
      "3  103l     A         24      151        PF00959  Phage_lysozyme   \n",
      "4  103m     A          7      113        PF00042          Globin   \n",
      "\n",
      "  AUTH_PDBRES_START AUTH_PDBRES_START_INS_CODE AUTH_PDBRES_END  \\\n",
      "0                 6                                        112   \n",
      "1                24                                        148   \n",
      "2                 6                                        112   \n",
      "3                24                                        148   \n",
      "4                 6                                        112   \n",
      "\n",
      "  AUTH_PDBRES_END_INS_CODE UNIPROT_ACCESSION  UNP_START  UNP_END  \n",
      "0                                     P02185          7      113  \n",
      "1                                     P00720         24      148  \n",
      "2                                     P02185          7      113  \n",
      "3                                     P00720         24      148  \n",
      "4                                     P02185          7      113  \n"
     ]
    }
   ],
   "source": [
    "import ecc_tools as tools\n",
    "ipdb = 0\n",
    "printing = True\n",
    "print('seq:',int(pdb[ipdb,1]))\n",
    "\n",
    "\n",
    "\n",
    "s0,cols_removed, s_index, tpdb, orig_seq_len = data_processing(data_path, pfam_id, ipdb,\\\n",
    "                gap_seqs=0.2, gap_cols=0.2, prob_low=0.004, conserved_cols=0.9, printing=printing, \\\n",
    "                                                               out_dir=processed_data_dir)\n",
    "print('\\n\\n\\nPreprocessed reference Sequence: ', s0[tpdb])\n",
    "\n",
    "# npy2fa does not remove cols this way we are as close to original as possible\n",
    "msa_outfile, ref_outfile, s0, cols_removed, s_index, tpdb, orig_seq_len  = tools.npy2fa(pfam_id, msa_npy_file,\\\n",
    "                                                                                        pdb_ref_file=pdb_ref_file,\\\n",
    "                                                                                        ipdb=ipdb, preprocess=True,\\\n",
    "                                                                                        gap_seqs=.2, gap_cols=.2, \\\n",
    "                                                                                        prob_low=.004, \\\n",
    "                                                                                        conserved_cols=.9, \\\n",
    "                                                                                        letter_format=False, \\\n",
    "                                                                                        first_10=False)\n",
    "\n",
    "print('\\n\\nfirst 50 S: ', s0.shape, '\\n\\n')\n",
    "pdb_id = pdb_df.iloc[ipdb]['pdb_id']\n",
    "pdb_chain = pdb_df.iloc[ipdb]['chain']\n",
    "\n",
    "pdb_pfam_map_file = Path('%s/protein_data/pdb_data/pdb_pfam_mapping.csv' % DCA_dir)\n",
    "pdb_map_df = pd.read_csv(pdb_pfam_map_file, sep=',', header=1)\n",
    "print(pdb_map_df.head())\n",
    "\n",
    "pdb_id_map_df = pdb_map_df.loc[pdb_map_df['PDB']==pdb_id.lower()]\n",
    "pdb_pfam_map = pdb_id_map_df.loc[pdb_id_map_df['CHAIN']==pdb_chain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8737e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "if computing_pydca_mf:\n",
    "    def compute_sequences_weight(alignment_data=None, seqid=None):\n",
    "        \"\"\"Computes weight of sequences. The weights are calculated by lumping\n",
    "        together sequences whose identity is greater that a particular threshold.\n",
    "        For example, if there are m similar sequences, each of them will be assigned\n",
    "        a weight of 1/m. Note that the effective number of sequences is the sum of\n",
    "        these weights.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            alignmnet_data : np.array()\n",
    "                Numpy 2d array of the alignment data, after the alignment is put in\n",
    "                integer representation\n",
    "            seqid : float\n",
    "                Value at which beyond this sequences are considered similar. Typical\n",
    "                values could be 0.7, 0.8, 0.9 and so on\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            seqs_weight : np.array()\n",
    "                A 1d numpy array containing computed weights. This array has a size\n",
    "                of the number of sequences in the alignment data.\n",
    "        \"\"\"\n",
    "        alignment_shape = alignment_data.shape\n",
    "        num_seqs = alignment_shape[0]\n",
    "        seqs_len = alignment_shape[1]\n",
    "        seqs_weight = np.zeros((num_seqs,), dtype=np.float64)\n",
    "        inv_seqs_weight = np.zeros((num_seqs,), dtype=np.float64)\n",
    "\n",
    "        #count similar sequences\n",
    "        for i in range(num_seqs):\n",
    "            seq_i = alignment_data[i]\n",
    "            for j in range(num_seqs):\n",
    "                seq_j = alignment_data[j]\n",
    "                iid = np.sum(seq_i==seq_j)\n",
    "                if np.float64(iid)/np.float64(seqs_len) > seqid:\n",
    "                    seqs_weight[i] += 1\n",
    "        #compute the weight of each sequence in the alignment\n",
    "        for i in range(num_seqs): inv_seqs_weight[i] = 1.0/float(seqs_weight[i])\n",
    "        np.save('first10_seq_weight_pydca.npy', seqs_weight)\n",
    "        return seqs_weight, inv_seqs_weight\n",
    "\n",
    "\n",
    "    def compute_single_site_freqs(alignment_data=None,\n",
    "            num_site_states=None, seqs_weight=None):\n",
    "        \"\"\"Computes single site frequency counts for a particular aligmnet data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            alignment_data : np.array()\n",
    "                A 2d numpy array of alignment data represented in integer form.\n",
    "\n",
    "            num_site_states : int\n",
    "                An integer value fo the number of states a sequence site can have\n",
    "                including a gap state. Typical value is 5 for RNAs and 21 for\n",
    "                proteins.\n",
    "\n",
    "            seqs_weight : np.array()\n",
    "                A 1d numpy array of sequences weight\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            single_site_freqs : np.array()\n",
    "                A 2d numpy array of of data type float64. The shape of this array is\n",
    "                (seqs_len, num_site_states) where seqs_len is the length of sequences\n",
    "                in the alignment data.\n",
    "        \"\"\"\n",
    "        alignment_shape = alignment_data.shape\n",
    "        #num_seqs = alignment_shape[0]\n",
    "        seqs_len = alignment_shape[1]\n",
    "        m_eff = np.sum(seqs_weight)\n",
    "        print('pydca m_eff = %f' % m_eff)\n",
    "        print(m_eff)\n",
    "        single_site_freqs = np.zeros(shape = (seqs_len, num_site_states),\n",
    "            dtype = np.float64)\n",
    "        for i in range(seqs_len):\n",
    "\n",
    "            #for a in range(1, num_site_states + 1):#we need gap states single site freqs too\n",
    "            for a in range(num_site_states-1):#we need gap states single site freqs too  ## ECC CHANGE \n",
    "                                                ## why do you need gap states? also shifted aa range to 0-20\n",
    "\n",
    "                column_i = alignment_data[:,i]\n",
    "                freq_ia = np.sum((column_i==a)*seqs_weight)\n",
    "                # single_site_freqs[i, a-1] = freq_ia/m_eff\n",
    "                single_site_freqs[i, a] = freq_ia/m_eff ## ECC CHANGE -- index offset no longer necessary\n",
    "                if freq_ia >0:\n",
    "                    print('site %d-%d freq and count: ' % (i, a), single_site_freqs[i,a-1], np.sum((column_i==a)))\n",
    "\n",
    "        return single_site_freqs\n",
    "\n",
    "\n",
    "    def compute_pair_site_freqs(alignment_data=None, num_site_states=None, seqs_weight=None):\n",
    "        \"\"\"Computes pair site frequencies for an alignmnet data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            alignment_data : np.array()\n",
    "                A 2d numpy array conatining alignment data. The residues in the\n",
    "                alignment are in integer representation.\n",
    "            num_site_states : int\n",
    "                The number of possible states including gap state that sequence\n",
    "                sites can accomodate. It must be an integer\n",
    "            seqs_weight:\n",
    "                A 1d numpy array of sequences weight\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            pair_site_freqs : np.array()\n",
    "                A 3d numpy array of shape\n",
    "                (num_pairs, num_site_states, num_site_states) where num_pairs is\n",
    "                the number of unique pairs we can form from sequence sites. The\n",
    "                pairs are assumed to in the order (0, 1), (0, 2) (0, 3), ...(0, L-1),\n",
    "                ... (L-1, L). This ordering is critical and any change must be\n",
    "                documented.\n",
    "        \"\"\"\n",
    "        alignment_shape = alignment_data.shape\n",
    "        num_seqs = alignment_shape[0]\n",
    "        seqs_len = alignment_shape[1]\n",
    "        num_site_pairs = (seqs_len -1)*seqs_len/2\n",
    "        num_site_pairs = np.int64(num_site_pairs)\n",
    "        m_eff = np.sum(seqs_weight)\n",
    "        pair_site_freqs = np.zeros(\n",
    "            shape=(num_site_pairs, num_site_states - 1, num_site_states - 1),\n",
    "            dtype = np.float64\n",
    "        )\n",
    "        for i in range(seqs_len - 1):\n",
    "            column_i = alignment_data[:, i]\n",
    "            for j in range(i+1, seqs_len):\n",
    "                pair_site = int((seqs_len * (seqs_len - 1)/2) - (seqs_len - i) * ((seqs_len - i) - 1)/2  + j  - i - 1)\n",
    "                column_j = alignment_data[:, j]\n",
    "                ## ECC CHANGE\n",
    "                # for a in range(1, num_site_states):\n",
    "                for a in range(num_site_states-1):\n",
    "                    count_ai = column_i==a\n",
    "\n",
    "                    ## ECC CHANGE\n",
    "                    # for b in range(1, num_site_states):\n",
    "                    for b in range(num_site_states-1):\n",
    "                        count_bj = column_j==b\n",
    "                        count_ai_bj = count_ai * count_bj\n",
    "                        freq_ia_jb = np.sum(count_ai_bj*seqs_weight)\n",
    "                        #if freq_ia_jb > 0.0:\n",
    "                            # print('freq for %d-%d, %d-%d:' %(i,a,j,b), freq_ia_jb)\n",
    "                        # pair_site_freqs[pair_site, a-1, b-1] += freq_ia_jb/m_eff\n",
    "                        pair_site_freqs[pair_site, a, b] += freq_ia_jb/m_eff ## ECC CHANGE -- shift index not needed\n",
    "\n",
    "        return pair_site_freqs\n",
    "\n",
    "    def get_reg_single_site_freqs(single_site_freqs = None, seqs_len = None,\n",
    "            num_site_states = None, pseudocount = None):\n",
    "        \"\"\"Regularizes single site frequencies.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            single_site_freqs : np.array()\n",
    "                A 2d numpy array of single site frequencies of shape\n",
    "                (seqs_len, num_site_states). Note that gap state frequencies are                         \n",
    "                included in this data.                                                                   \n",
    "            seqs_len : int\n",
    "                The length of sequences in the alignment data                                            \n",
    "            num_site_states : int\n",
    "                Total number of states that a site in a sequence can accommodate. It                     \n",
    "                includes gap states.                                                                     \n",
    "            pseudocount : float\n",
    "                This is the value of the relative pseudo count of type float.\n",
    "                theta = lambda/(meff + lambda), where meff is the effective number of\n",
    "                sequences and lambda is the real pseudo count.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            reg_single_site_freqs : np.array()\n",
    "                A 2d numpy array of shape (seqs_len, num_site_states) of single site\n",
    "                frequencies after they are regularized.\n",
    "        \"\"\"\n",
    "        reg_single_site_freqs = single_site_freqs\n",
    "        theta_by_q = np.float64(pseudocount)/np.float64(num_site_states)\n",
    "        for i in range(seqs_len):\n",
    "            for a in range(num_site_states-1): ## ECC CHANGE -- not includeing gap states\n",
    "                reg_single_site_freqs[i, a] = theta_by_q + \\\n",
    "                    (1.0 - pseudocount)*reg_single_site_freqs[i, a]\n",
    "                print('site %d-%d regularized freq: ' % (i, a), reg_single_site_freqs[i,a])\n",
    "\n",
    "        return reg_single_site_freqs\n",
    "\n",
    "    def get_reg_pair_site_freqs(pair_site_freqs = None, seqs_len = None,\n",
    "            num_site_states = None, pseudocount = None):\n",
    "        \"\"\"Regularizes pair site frequencies\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            pair_site_freqs : np.array()\n",
    "                A 3d numpy array of shape (num_unique_site_pairs, num_site_states -1,\n",
    "                num_site_states -1) containing raw pair site frequency counts where\n",
    "                num_unique_site_pairs is the total number of unique site pairs\n",
    "                excluding self pairing. Note that the order in with the pairing is\n",
    "                done is important. It must be taken in (0, 1), (0,2), ...,\n",
    "                (0, seqs_len-1), (1, 2)... order. Note that this data does not\n",
    "                contain pairings with gap states.\n",
    "            seqs_len : int\n",
    "                The length of sequences in the alignment.\n",
    "            num_site_states : int\n",
    "                The total number of states that a site in the sequences can\n",
    "                accommodate. This includes gap states.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            reg_pair_site_freqs : np.array()\n",
    "                A numpy array of shape the same as pair_site_freqs\n",
    "        \"\"\"\n",
    "        reg_pair_site_freqs = pair_site_freqs\n",
    "        theta_by_qsqrd = pseudocount/float(num_site_states * num_site_states)\n",
    "        pair_counter = 0\n",
    "        for i in range(seqs_len - 1):\n",
    "            for j in range(i + 1, seqs_len):\n",
    "                for a in range(num_site_states-1):\n",
    "                    for b in range(num_site_states-1):\n",
    "                        reg_pair_site_freqs[pair_counter, a, b] = theta_by_qsqrd + \\\n",
    "                            (1.0 - pseudocount)*reg_pair_site_freqs[pair_counter, a, b]\n",
    "                pair_counter += 1\n",
    "        return reg_pair_site_freqs\n",
    "    \n",
    "    \n",
    "    theta = .2\n",
    "    #try:\n",
    "     #   seq_weight = np.load('first10_seq_weight_pydca.npy')\n",
    "    #except(FileNotFoundError):\n",
    "    seq_int_count, seq_weight = compute_sequences_weight(alignment_data=s0, seqid=float(1.-theta))\n",
    "    pydca_fi = compute_single_site_freqs(alignment_data=s0, num_site_states=21, seqs_weight=seq_weight)\n",
    "\n",
    "    reg_pydca_fi = get_reg_single_site_freqs(single_site_freqs = pydca_fi, seqs_len = s0.shape[1],\n",
    "        num_site_states = 21, pseudocount = .5)\n",
    "    pydca_fij = compute_pair_site_freqs(alignment_data=s0, num_site_states=21, seqs_weight=seq_weight)\n",
    "    reg_pydca_fij = get_reg_pair_site_freqs(pair_site_freqs = pydca_fij, seqs_len = s0.shape[1],\n",
    "        num_site_states = 21, pseudocount = .5)\n",
    "else:\n",
    "    pydca_fi = np.load('%s%s_pydca_unreg_fi_preproc.npy' % (out_dir, pfam_id))\n",
    "    reg_pydca_fi = np.load('%s%s_pydca_fi_preproc.npy' % (out_dir, pfam_id))\n",
    "    pydca_fij = np.load('%s%s_pydca_unreg_fij_preproc.npy' % (out_dir, pfam_id))\n",
    "    reg_pydca_fij = np.load('%s%s_pydca_fij_preproc.npy' % (out_dir, pfam_id))\n",
    "    seq_weight = np.load('%s%s_pydca_seq_weight_preproc.npy' % (out_dir, pfam_id))\n",
    "    # files save in pydca_demo.ipynb\n",
    "    #     np.save('%s%s_pydca_fields_preproc.npy' % (out_dir, pfam_id), fields_ij)\n",
    "    #     np.save('%s%s_pydca_couplings_preproc.npy' % (out_dir, pfam_id), couplings)\n",
    "    #     np.save('%s%s_pydca_corr_preproc.npy' % (out_dir, pfam_id), corr_mat)\n",
    "    #     np.save('%s%s_pydca_unreg_fij_preproc.npy' % (out_dir, pfam_id), fij)\n",
    "    #     np.save('%s%s_pydca_unreg_fi_preproc.npy' % (out_dir, pfam_id), fi)\n",
    "    #     np.save('%s%s_pydca_fij_preproc.npy' % (out_dir, pfam_id), reg_fij)\n",
    "    #     np.save('%s%s_pydca_fi_preproc.npy' % (out_dir, pfam_id), reg_fi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbda7df",
   "metadata": {},
   "source": [
    "# Comparing Frequency (single-site/pair-site) for first 10 AA\n",
    "* We want to number of effective to be the same (m_eff/meff)\n",
    "* We want counts to be the same\n",
    "* from here single site should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43014468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6573, 160)\n",
      "(6573, 160)\n",
      "ma_inv (sequences weight shape:  (6573,)\n",
      "tais meff = 4355.021797\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60096/2347540762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmf_di\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcinv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi_pydca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfij_pydca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_pydca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_inv_pydca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_pydca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2d_pydcak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdi_pydca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma_inv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_ints\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;34m=\u001b[0m \u001b[0mdirect_info_dca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_wt_outfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_wt_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst10\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c[0]:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c_pydca[0]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_pydca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/DCA_ER/inference_dca.py\u001b[0m in \u001b[0;36mdirect_info_dca\u001b[0;34m(s0, q, theta, pseudo_weight, seq_wt_outfile, first10)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseq_wt_outfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfij\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfi_pydca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfij_pydca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma_inv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_ints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpseudo_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_weight_outfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_wt_outfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst10\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpseudo_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/DCA_ER/inference_dca.py\u001b[0m in \u001b[0;36mfrequency\u001b[0;34m(s0, q, theta, pseudo_weight, seq_weight_outfile, first10)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mcount_bj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_j\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         \u001b[0mcount_ai_bj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_ai\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcount_bj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0mfreq_ia_jb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_ai_bj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mseqs_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                         \u001b[0mfij_pydca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpair_site\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfreq_ia_jb\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmeff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute Frequencies printing everything out\n",
    "from inference_dca import direct_info_dca\n",
    "print(s0.shape)\n",
    "seq_wt_file = None\n",
    "seq_wt_file = '%s/protein_data/data_processing_output/seq_weight_%s.npy' % (DCA_ER_dir, pfam_id)\n",
    "\n",
    "# ----------- DCA DI (MF) calculation --------------------------------------------- #\n",
    "\n",
    "mf_di, fi, fij, c, cinv, w, w2d, fi_pydca, fij_pydca, c_pydca, c_inv_pydca, w_pydca, w2d_pydcak, di_pydca, ma_inv,seq_ints \\\n",
    "= direct_info_dca(s0, seq_wt_outfile=seq_wt_file, first10=False)\n",
    "print('c[0]:',c[0])\n",
    "print('c_pydca[0]', c_pydca[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pydca sequences weight array length: ', seq_weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0aaefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ma_inv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7458e286",
   "metadata": {},
   "source": [
    "### Difference in Sequence weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('\\n\\nthe difference between our seq_weight (ma_inv) and their seq_weights for all %d sequences is %d.... QED\\n\\n' % \n",
    "      (s0.shape[0], abs(seq_weight - ma_inv).sum()))\n",
    "\n",
    "\n",
    "print(seq_weight[:15])\n",
    "print(ma_inv[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65790f24",
   "metadata": {},
   "source": [
    "### Frequency Matrix Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fi.shape)\n",
    "print(pydca_fi.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e96d7",
   "metadata": {},
   "source": [
    "### Difference in Single-Site Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09effa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_diff = fi-reg_pydca_fi\n",
    "print(fi_diff[0])\n",
    "print(fi_diff[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e198a7",
   "metadata": {},
   "source": [
    "### Pair-Site Frequency differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0046cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fij.shape)\n",
    "print(pydca_fij.shape)\n",
    "pair_counter = 0\n",
    "fij_diffs = []\n",
    "for i in range(s0.shape[1] - 1):\n",
    "    for j in range(i + 1, s0.shape[1]):\n",
    "        for a in range(21-1):\n",
    "            for b in range(21-1):\n",
    "                fij_diffs.append(reg_pydca_fij[pair_counter, a, b] - fij[i,j,a,b]) \n",
    "        pair_counter +=1\n",
    "\n",
    "print(np.sum(fij_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72872322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7edb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d656bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
