{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import Bio.PDB, warnings\n",
    "from Bio import BiopythonWarning\n",
    "warnings.simplefilter('ignore', BiopythonWarning)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import timeit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # --- Import our Code ---# #\n",
    "#import emachine as EM\n",
    "from direct_info import direct_info\n",
    "\n",
    "import expectation_reflection as ER\n",
    "# import data processing and general DCA_ER tools\n",
    "from data_processing import data_processing_msa2pdb\n",
    "import ecc_tools as tools\n",
    "from pathlib import Path\n",
    "np.random.seed(1)\n",
    "\n",
    "from Bio.PDB import *\n",
    "\n",
    "#from Bio.SubsMat.MatrixInfo import blosum62\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63cc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new = True\n",
    "printing = True\n",
    "removing_cols = True\n",
    "\n",
    "\n",
    "data_path = Path('/data/cresswellclayec/DCA_ER/Pfam-A.full')\n",
    "data_path = Path('/data/cresswellclayec/Pfam-A.full')\n",
    "\n",
    "# Define data directories\n",
    "DCA_ER_dir = '/data/cresswellclayec/DCA_ER' # Set DCA_ER directory\n",
    "biowulf_dir = '%s/biowulf_full' % DCA_ER_dir\n",
    "\n",
    "out_dir = '%s/protein_data/di/' % biowulf_dir\n",
    "processed_data_dir = \"%s/protein_data/data_processing_output\" % biowulf_dir\n",
    "pdb_dir = '%s/protein_data/pdb_data/' % biowulf_dir\n",
    "\n",
    "\n",
    "pfam_dir = \"/fdb/fastadb/pfam\"\n",
    "\n",
    "from data_processing import pdb2msa, data_processing_pdb2msa\n",
    "\n",
    "\n",
    "import gzip, shutil\n",
    "def gunzip(file_path, output_path):\n",
    "    print('Unzipping %s to %s' % (file_path, output_path))\n",
    "    with gzip.open(file_path,\"rb\") as f_in, open(output_path,\"wb\") as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "\n",
    "n_cpus = 20\n",
    "pdb_id = '1zdr'\n",
    "pdb_id = '5r1k'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prody_df = pd.read_csv('%s/%s_pdb_df.csv' % (pdb_dir, pdb_id))\n",
    "pdb2msa_row  = prody_df.iloc[0]\n",
    "#try:\n",
    "print(pdb2msa_row)\n",
    "pfam_id = pdb2msa_row['Pfam']\n",
    "pdb_id = pdb2msa_row['PDB ID']\n",
    "pdb_chain = pdb2msa_row['Chain']\n",
    "\n",
    "ref_outfile = Path(processed_data_dir, '%s_ref.fa' % pfam_id)\n",
    "\n",
    "pfam_dimensions_file = \"%s/%s_%s_pfam_dimensions.npy\" % (processed_data_dir, pdb_id, pfam_id)\n",
    "pfam_dimensions = np.load(pfam_dimensions_file)\n",
    "if len(pfam_dimensions)==7:\n",
    "    [n_col, n_seq, m_eff, ct_ER, ct_MF, ct_PMF, ct_PLM] = pfam_dimensions\n",
    "elif len(pfam_dimensions)==6: # new pfam_dimensions created in run_method_comparison. we dont need MF..\n",
    "    [n_col, n_seq, m_eff, ct_ER, ct_PMF, ct_PLM] = pfam_dimensions\n",
    "elif len(pfam_dimensions)==3:\n",
    "    [n_col, n_seq, m_eff] = pfam_dimensions\n",
    "\n",
    "pdb_id = pdb2msa_row['PDB ID']\n",
    "pfam_id = pdb2msa_row['Pfam']\n",
    "# update Prody search DF (use same filename as pdb2msa() in data_processing\n",
    "\n",
    "# LOAD MSA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dfcdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_file = \"%s/%s_%s_dp.pkl\" % (processed_data_dir, pdb_id, pfam_id)\n",
    "if not os.path.exists(dp_file):\n",
    "    print('\\nPDB DF with associated Protein Families\\n', prody_df.loc[:,  [column for column in prody_df.columns if column not in ['locations', 'PDB Sequence']]].head())\n",
    "    print(\"\\n\\nLooping through Prody Search DataFrame:\", prody_df.head())\n",
    "    rows_to_drop = []\n",
    "    for ir, pdb2msa_row in enumerate(prody_df.iterrows()):\n",
    "        print('\\n\\nGetting msa with following pdb2msa entry:\\n', pdb2msa_row)\n",
    "        try:\n",
    "            dp_result =  data_processing_pdb2msa(data_path, prody_df.iloc[pdb2msa_row[0]], gap_seqs=0.2, gap_cols=0.2, prob_low=0.004,\n",
    "                                   conserved_cols=0.8, printing=True, out_dir=processed_data_dir, pdb_dir=pdb_dir, letter_format=False,\n",
    "                                   remove_cols=True, create_new=True)\n",
    "            if dp_result is not None:\n",
    "                [s0, removed_cols, s_index, tpdb, pdb_s_index] = dp_result\n",
    "                break\n",
    "            else:\n",
    "                rows_to_drop.append(ir)\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print('row %d got exception: ' % ir , e)\n",
    "            print('moving on.. ')\n",
    "            pass\n",
    "    with open(dp_file, 'wb') as dp_handle:\n",
    "        pickle.dump(dp_result, dp_handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(dp_file, 'rb') as dp_handle:\n",
    "        dp_result = pickle.load(dp_handle)\n",
    "    [s0, removed_cols, s_index, tpdb, pdb_s_index] = dp_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16649c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_seq_wt = np.transpose(s0)\n",
    "print('s0: ', s0.shape)\n",
    "print('s0 seq_wt: ', s0_seq_wt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f60b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of positions\n",
    "n_var = s0_seq_wt.shape[0]\n",
    "n_seq = s0_seq_wt.shape[1]\n",
    "\n",
    "print(\"Number of residue positions:\",n_var)\n",
    "print(\"Number of sequences:\",n_seq)\n",
    "\n",
    "# number of aminoacids at each position\n",
    "mx = np.array([len(np.unique(s0_seq_wt[:,i])) for i in range(n_seq)])\n",
    "print(\"Number of different amino acids at each position\",mx)\n",
    "\n",
    "mx_cumsum = np.insert(mx.cumsum(),0,0)\n",
    "i1i2 = np.stack([mx_cumsum[:-1],mx_cumsum[1:]]).T\n",
    "\n",
    "\n",
    "# number of variables\n",
    "mx_sum = mx.sum()\n",
    "print(\"Total number of variables\",mx_sum)\n",
    "\n",
    "# number of bias term\n",
    "n_linear = mx_sum - n_seq\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "s = onehot_encoder.fit_transform(s0_seq_wt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation Reflection\n",
    "#=========================================================================================\n",
    "def predict_w(s,i0,i1i2,niter_max,l2):\n",
    "    #print('i0:',i0)\n",
    "    i1,i2 = i1i2[i0,0],i1i2[i0,1]\n",
    "\n",
    "    x = np.hstack([s[:,:i1],s[:,i2:]])\n",
    "    y = s[:,i1:i2]\n",
    "\n",
    "    h01,w1 = ER.fit(x,y,niter_max,l2)\n",
    "\n",
    "    return h01,w1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1a550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_file = \"%s/%s_%s_wT.npy\" % (processed_data_dir, pdb_id, pfam_id)\n",
    "if os.path.exists(w_file) and not create_new:\n",
    "    w = np.load(w_file)\n",
    "else:\n",
    "    #-------------------------------\n",
    "    # parallel\n",
    "    start_time = timeit.default_timer()\n",
    "    #res = Parallel(n_jobs = 4)(delayed(predict_w)\\\n",
    "    #res = Parallel(n_jobs = 8)(delayed(predict_w)\\\n",
    "    res = Parallel(n_jobs = n_cpus-2)(delayed(predict_w)\\\n",
    "            (s,i0,i1i2,niter_max=10,l2=100.0)\\\n",
    "            for i0 in range(n_var))\n",
    "\n",
    "    run_time = timeit.default_timer() - start_time\n",
    "    print('run time:',run_time)\n",
    "    ## This above line seems wrong, seems like the following for loop should be moved up?? not sure if this is some \n",
    "    ## python implementation or just wrong\n",
    "    #-------------------------------\n",
    "    for i0 in range(n_var):\n",
    "        i1,i2 = i1i2[i0,0],i1i2[i0,1]\n",
    "\n",
    "        h01 = res[i0][0]\n",
    "        w1 = res[i0][1]\n",
    "\n",
    "        h0[i1:i2] = h01\n",
    "        w[:i1,i1:i2] = w1[:i1,:]\n",
    "        w[i2:,i1:i2] = w1[i1:,:]\n",
    "\n",
    "    # make w symmetric\n",
    "    w = (w + w.T)/2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03942c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
