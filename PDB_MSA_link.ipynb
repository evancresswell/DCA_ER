{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec81da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import Bio.PDB, warnings\n",
    "pdb_list = Bio.PDB.PDBList()\n",
    "pdb_parser = Bio.PDB.PDBParser()\n",
    "from scipy.spatial import distance_matrix\n",
    "from Bio import BiopythonWarning\n",
    "warnings.simplefilter('ignore', BiopythonWarning)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import timeit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # --- Import our Code ---# #\n",
    "#import emachine as EM\n",
    "from direct_info import direct_info\n",
    "\n",
    "# import data processing and general DCA_ER tools\n",
    "from data_processing import data_processing_pdb2msa, pdb2msa\n",
    "import ecc_tools as tools\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new = True\n",
    "printing = True\n",
    "removing_cols = True\n",
    "remove_diagonals = False\n",
    "\n",
    "\n",
    "data_path = Path('/data/cresswellclayec/DCA_ER/Pfam-A.full')\n",
    "\n",
    "\n",
    "# Define data directories\n",
    "DCA_ER_dir = '/data/cresswellclayec/DCA_ER' # Set DCA_ER directory\n",
    "biowulf_dir = '%s/biowulf_pdb2msa' % DCA_ER_dir\n",
    "\n",
    "\n",
    "out_dir = '%s/protein_data/di/' % biowulf_dir\n",
    "out_metric_dir = '%s/protein_data/metrics/' % biowulf_dir\n",
    "\n",
    "processed_data_dir = \"%s/protein_data/data_processing_output\" % biowulf_dir\n",
    "pdb_dir = '%s/protein_data/pdb_data/' % biowulf_dir\n",
    "\n",
    "pdb_path = \"/pdb/pdb/zd/pdb1zdr.ent.gz\"\n",
    "# pdb_path = sys.argv[1]\n",
    "n_cpus = 6\n",
    "print('\\n\\nUnzipping %s' % pdb_path)\n",
    "\n",
    "unzipped_pdb_filename = os.path.basename(pdb_path).replace(\".gz\", \"\")\n",
    "\n",
    "pdb_out_path = \"%s%s\" % (pdb_dir, unzipped_pdb_filename)\n",
    "print('Unzipping %s to %s' % (pdb_path, pdb_out_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e1bf7",
   "metadata": {},
   "source": [
    "## Using PDB-->MSA with Prody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af02393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, shutil\n",
    "def gunzip(file_path,output_path):\n",
    "    with gzip.open(file_path,\"rb\") as f_in, open(output_path,\"wb\") as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "        \n",
    "unzipped_pdb_filename = os.path.basename(pdb_path).replace(\".gz\", \"\")\n",
    "\n",
    "pdb_out_path = \"%s%s\" % (pdb_dir, unzipped_pdb_filename)\n",
    "print('Unzipping %s to %s' % (pdb_path, pdb_out_path))\n",
    "\n",
    "gunzip(pdb_path, pdb_out_path)\n",
    "print(pdb_out_path)\n",
    "print(pdb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a04e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdb_out_path)\n",
    "print(pdb_dir)\n",
    "pdb2msa_results = pdb2msa(pdb_out_path, pdb_dir, create_new=True)\n",
    "print(pdb2msa_results)\n",
    "\n",
    "if len(pdb2msa_results) > 1:\n",
    "    fasta_file = pdb2msa_results[0]\n",
    "    prody_df = pdb2msa_results[1]\n",
    "else:\n",
    "    prody_df = pdb2msa_results[0]\n",
    "\n",
    "\n",
    "                                                                                                                                                                                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f00002",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPDB DF with associated Protein Families\\n', prody_df.loc[:,  [column for column in prody_df.columns if column not in ['locations', 'PDB Sequence']]].head())\n",
    "\n",
    "\n",
    "for ir, pdb2msa_row in enumerate(prody_df.iterrows()):\n",
    "    print('\\n\\nGetting msa with following pdb2msa entry:\\n', pdb2msa_row)\n",
    "    try:\n",
    "        dp_result =  data_processing_pdb2msa(data_path, prody_df.iloc[pdb2msa_row[0]], gap_seqs=0.2, gap_cols=0.2, prob_low=0.004,\n",
    "                               conserved_cols=0.8, printing=True, out_dir=processed_data_dir, pdb_dir=pdb_dir, letter_format=False,\n",
    "                               remove_cols=True, create_new=True, n_cpu=min(2, n_cpus))\n",
    "        if dp_result is not None:\n",
    "            [s0, removed_cols, s_index, tpdb] = dp_result\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print('row %d got exception: ' % ir , e)\n",
    "        print('moving on.. ')\n",
    "        pass\n",
    "pfam_id = pdb2msa_row[1]['Pfam']\n",
    "pdb_id = pdb2msa_row[1]['PDB ID']\n",
    "\n",
    "print('Done...')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of positions\n",
    "n_var = s0.shape[1]\n",
    "n_seq = s0.shape[0]\n",
    "\n",
    "print(\"Number of residue positions:\",n_var)\n",
    "print(\"Number of sequences:\",n_seq)\n",
    "\n",
    "# number of aminoacids at each position\n",
    "mx = np.array([len(np.unique(s0[:,i])) for i in range(n_var)])\n",
    "#mx = np.array([m for i in range(n_var)])\n",
    "print(\"Number of different amino acids at each position\",mx)\n",
    "\n",
    "mx_cumsum = np.insert(mx.cumsum(),0,0)\n",
    "i1i2 = np.stack([mx_cumsum[:-1],mx_cumsum[1:]]).T \n",
    "# print(\"(Sanity Check) Column indices of first and (\",i1i2[0],\") and last (\",i1i2[-1],\") positions\")\n",
    "# print(\"(Sanity Check) Column indices of second and (\",i1i2[1],\") and second to last (\",i1i2[-2],\") positions\")\n",
    "\n",
    "\n",
    "# number of variables\n",
    "mx_sum = mx.sum()\n",
    "print(\"Total number of variables\",mx_sum)\n",
    "\n",
    "# number of bias term\n",
    "n_linear = mx_sum - n_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "# s is OneHot encoder format, s0 is original sequnce matrix\n",
    "s = onehot_encoder.fit_transform(s0)\n",
    "# print(\"Amino Acid sequence Matrix\\n\",s0)\n",
    "# print(\"OneHot sequence Matrix\\n\",s)\n",
    "# print(\"An individual element of the OneHot sequence Matrix (size:\",\n",
    "#      s.shape,\") --> \",s[0], \" has length \",s[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define wight matrix with variable for each possible amino acid at each sequence position\n",
    "w = np.zeros((mx.sum(),mx.sum())) \n",
    "h0 = np.zeros(mx.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import expectation_reflection as ER\n",
    "from direct_info import direct_info\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation Reflection\n",
    "#=========================================================================================\n",
    "def predict_w(s,i0,i1i2,niter_max,l2):\n",
    "    #print('i0:',i0)\n",
    "    i1,i2 = i1i2[i0,0],i1i2[i0,1]\n",
    "\n",
    "    x = np.hstack([s[:,:i1],s[:,i2:]])\n",
    "    y = s[:,i1:i2]\n",
    "\n",
    "    h01,w1 = ER.fit(x,y,niter_max,l2)\n",
    "\n",
    "    return h01,w1\n",
    "\n",
    "create_new=False\n",
    "w_file = \"%s/%s_%s_w.npy\" % (processed_data_dir, pdb_id, pfam_id)\n",
    "if os.path.exists(w_file) and not create_new:\n",
    "    w = np.load(w_file)\n",
    "else:\n",
    "    #-------------------------------\n",
    "    # parallel\n",
    "    start_time = timeit.default_timer()\n",
    "    #res = Parallel(n_jobs = 4)(delayed(predict_w)\\\n",
    "    #res = Parallel(n_jobs = 8)(delayed(predict_w)\\\n",
    "    res = Parallel(n_jobs = 32)(delayed(predict_w)\\\n",
    "            (s,i0,i1i2,niter_max=10,l2=100.0)\\\n",
    "            for i0 in range(n_var))\n",
    "\n",
    "    run_time = timeit.default_timer() - start_time\n",
    "    print('run time:',run_time)\n",
    "    ## This above line seems wrong, seems like the following for loop should be moved up?? not sure if this is some \n",
    "    ## python implementation or just wrong\n",
    "    #-------------------------------\n",
    "    for i0 in range(n_var):\n",
    "        i1,i2 = i1i2[i0,0],i1i2[i0,1]\n",
    "\n",
    "        h01 = res[i0][0]\n",
    "        w1 = res[i0][1]\n",
    "\n",
    "        h0[i1:i2] = h01\n",
    "        w[:i1,i1:i2] = w1[:i1,:]\n",
    "        w[i2:,i1:i2] = w1[i1:,:]\n",
    "\n",
    "    # make w symmetric\n",
    "    w = (w + w.T)/2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not create_new and os.path.exists(\"%s/%s_%s_ER_di.npy\" % (out_dir, pdb_id, pfam_id)):\n",
    "    di = np.load(\"%s/%s_%s_ER_di.npy\" % (out_dir, pdb_id, pfam_id))\n",
    "else:\n",
    "    di = direct_info(s0,w)\n",
    "    np.save(\"%s/%s_%s_ER_di.npy\" % (out_dir, pdb_id, pfam_id), di)\n",
    "print(di)\n",
    "print(di.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdb2msa_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd4942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import prange as parallel_range\n",
    "import numpy as np\n",
    "import sys, os, errno\n",
    "import pandas as pd\n",
    "# Import Bio data processing features \n",
    "from Bio import SeqIO\n",
    "import Bio.PDB, warnings\n",
    "from Bio.PDB import *\n",
    "from scipy.spatial import distance_matrix\n",
    "from Bio import BiopythonWarning\n",
    "from Bio import pairwise2\n",
    "from Bio.SubsMat.MatrixInfo import blosum62\n",
    "from matplotlib import colors as mpl_colors\n",
    "import random\n",
    "import xml.etree.ElementTree as et\n",
    "from pathlib import Path\n",
    "from data_processing import data_processing, find_and_replace, data_processing_msa2pdb, load_msa\n",
    "from sklearn.metrics import roc_curve as roc_scikit\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "\n",
    "warnings.filterwarnings(\"error\")\n",
    "warnings.simplefilter('ignore', BiopythonWarning)\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "pdb_list = Bio.PDB.PDBList()\n",
    "pdb_parser = Bio.PDB.PDBParser()\n",
    "\n",
    "from ecc_tools import filter_residues, no_diag\n",
    "\n",
    "def contact_map_pdb2msa(pdb_df, pdb_file, removed_cols, pdb_out_dir='./', printing=True):\n",
    "    if printing:\n",
    "        print('\\n\\n#-----------------------#\\nGenerating Contact Map\\n#----------------------------#\\n')\n",
    "\n",
    "    pdb_id = pdb_df['PDB ID']\n",
    "    # pdb_file = pdb_list.retrieve_pdb_file(pdb_id)\n",
    "\n",
    "    pdb_start = pdb_df['ali_start'] - 1\n",
    "    pdb_end = pdb_df['ali_end'] \n",
    "    pdb_chain = pdb_df['Chain']\n",
    "    pdb_pp_index = pdb_df['Polypeptide Index']\n",
    "\n",
    "    pdb_model = pdb_parser.get_structure(str(pdb_id), pdb_file)[0]\n",
    "    found_pp_match = False\n",
    "    for chain in pdb_model.get_chains():\n",
    "        if chain.get_id() == pdb_chain:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "        ppb = PPBuilder().build_peptides(chain)\n",
    "\n",
    "        # # PYDCA method for getting polypeptide sequence...\n",
    "        poly_seq_new = [res.get_resname().strip() for res in filter_residues(pdb_model[chain.get_id()].get_list())]\n",
    "        print('new poly seq list: ', ''.join(poly_seq_new))\n",
    "\n",
    "        # Get full list of CA coords from poly_seq\n",
    "        poly_seq = list()\n",
    "        pp_ca_coords_full = list()\n",
    "        for i, pp in enumerate(ppb):\n",
    "            if i == pdb_pp_index:\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "            for char in str(pp.get_sequence()):\n",
    "                poly_seq.append(char)\n",
    "            poly_seq_ca_atoms = pp.get_ca_list()\n",
    "            pp_ca_coords_full.extend([a.get_coord() for a in poly_seq_ca_atoms])\n",
    "\n",
    "        print('\\nChain ', chain, ':\\n', ''.join(poly_seq))\n",
    "        poly_seq_range = poly_seq[pdb_start:pdb_end]\n",
    "        print( '\\n',''.join(poly_seq_range), '\\n')\n",
    "\n",
    "\n",
    "\n",
    "#         # # Search polyseq using haming distance..\n",
    "#         for str_index, aa_window in enumerate(window(''.join(poly_seq), len(queried_seq))):\n",
    "#             ham_dist = hamming_distance(queried_seq, aa_window)\n",
    "#             if ham_dist > mismatches:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 found_pp_match = True\n",
    "#                 pdb_start = str_index\n",
    "#                 pdb_end = str_index + len(queried_seq)\n",
    "#                 poly_seq_range = poly_seq[pdb_start:pdb_end]\n",
    "#                 print('Found Match!\\n')\n",
    "#                 print(''.join(poly_seq_range))\n",
    "#                 print(queried_seq)\n",
    "#                 break\n",
    "\n",
    "    n_amino_full = len(pp_ca_coords_full)\n",
    "\n",
    "    # Extract coordinates and sequence char in PDB-range\\\n",
    "    pp_ca_coords_full_range = pp_ca_coords_full[pdb_start:pdb_end]\n",
    "\n",
    "    ct_full = distance_matrix(pp_ca_coords_full, pp_ca_coords_full)\n",
    "\n",
    "\n",
    "\n",
    "    poly_seq_curated = np.delete(poly_seq_range, removed_cols)\n",
    "    pp_ca_coords_curated = np.delete(pp_ca_coords_full_range, removed_cols, axis=0)\n",
    "    ct = distance_matrix(pp_ca_coords_curated, pp_ca_coords_curated)\n",
    "\n",
    "    return ct, ct_full, n_amino_full, poly_seq_curated, poly_seq_range, poly_seq, pp_ca_coords_curated, pp_ca_coords_full_range\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct, ct_full, n_amino_full, poly_seq_curated, poly_seq_range, poly_seq, pp_ca_coords_curated, pp_ca_coords_full_range =  \\\n",
    "contact_map_pdb2msa(pdb2msa_row[1], pdb_out_path, removed_cols, pdb_out_dir=pdb_dir, printing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Direct Information from Expectation reflection:\\n\",di)\n",
    "print('ER DI shape: ' , di.shape)\n",
    "print(removed_cols)\n",
    "if not removing_cols:\n",
    "    er_di = np.delete(di, removed_cols,0)\n",
    "    er_di = np.delete(er_di, removed_cols,1)\n",
    "else:\n",
    "    er_di = di\n",
    "\n",
    "print('Final ER DI shape (cols removed): ', er_di.shape)\n",
    "if remove_diagonals: \n",
    "    ER_di = no_diag(er_di, 4, s_index)\n",
    "else:\n",
    "    ER_di = er_di\n",
    "    \n",
    "plt.title('ER direct information')\n",
    "plt.imshow(ER_di,cmap='rainbow',origin='lower')\n",
    "plt.xlabel('i')\n",
    "plt.ylabel('j')\n",
    "plt.clim(0,0.1)\n",
    "plt.colorbar(fraction=0.045, pad=0.05)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from ecc_tools import scores_matrix2dict\n",
    "print(s_index)\n",
    "ER_di_dict = scores_matrix2dict(ER_di, s_index, removed_cols, removing_cols=removing_cols)\n",
    "print(ER_di_dict[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a931803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecc_tools import roc_curve, roc_curve_new, precision_curve\n",
    "# find optimal threshold of distance\n",
    "ct_thres = np.linspace(4.,6.,18,endpoint=True)\n",
    "n = ct_thres.shape[0]\n",
    "\n",
    "\n",
    "# Initialize plotting\n",
    "iplot = [1,3,5,7,9,11,13]\n",
    "plt.figure(figsize=(9.0,3.2))\n",
    "\n",
    "# Initalize ROC-curve tile\n",
    "plt.subplot2grid((1,4),(0,0))\n",
    "plt.title('ROC various thres')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "\n",
    "ct_mat = ct\n",
    "\n",
    "\n",
    "auc_ER = np.zeros(n)\n",
    "for i in range(n):\n",
    "    try:\n",
    "        fpr, tpr, thresholds, auc = roc_curve_new(ct_mat, ER_di, ct_thres[i])\n",
    "        if i in iplot:\n",
    "            plt.plot(fpr, tpr, label='thres = %3.2f'%ct_thres[i])\n",
    "        auc_ER[i] = auc\n",
    "    except:\n",
    "        auc_ER[i] = 0\n",
    "  \n",
    "# Get ER method's best contact prediction\n",
    "i0_ER = np.argmax(auc_ER)\n",
    "print('ER auc max:',ct_thres[i0_ER],auc_ER[i0_ER])\n",
    "fpr0_ER, tpr0_ER, thresholds_ER, auc = roc_curve_new(ct_mat, ER_di, ct_thres[i0_ER])\n",
    "\n",
    "# ROC-curve tile settings\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])      \n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC ER method\")\n",
    "plt.legend(loc=\"lower right\") \n",
    "\n",
    "\n",
    "# Plot ROC, AUC and Precision for best ER contact prediction\n",
    "# AUC\n",
    "plt.subplot2grid((1,4),(0,1))\n",
    "plt.title('AUC max = %f' %(auc_ER[i0_ER]))\n",
    "plt.plot([ct_thres.min(),ct_thres.max()],[0.5,0.5],'k--')\n",
    "plt.plot(ct_thres,auc_ER,'k-')\n",
    "plt.plot(ct_thres[i0_ER],auc_ER[i0_ER], 'b*', markersize=10.)\n",
    "plt.xlim([ct_thres.min(),ct_thres.max()])\n",
    "plt.ylim([0,auc_ER.max()+0.1])\n",
    "plt.xlabel('distance threshold')\n",
    "plt.ylabel('AUC')\n",
    "# ROC\n",
    "plt.subplot2grid((1,4),(0,2))\n",
    "plt.title('ROC at thres = %3.2f'%(ct_thres[i0_ER]))\n",
    "plt.plot(fpr0_ER,tpr0_ER,'b-')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Precision-Recall\n",
    "plt.subplot2grid((1,4),(0,3))\n",
    "plt.title('Precision-Recall Curve')\n",
    "precision_ER, recall_ER, threshold = precision_curve(ct_mat, ER_di, ct_thres[i0_ER])\n",
    "print('\\nContact threshold: ', ct_thres[i0_ER])\n",
    "plt.plot( recall_ER, precision_ER, 'b-', label='thres = %s'%ct_thres[i0_ER])\n",
    "plt.xlabel('Recall (Sensitivity - P)')\n",
    "plt.ylabel('Precision (PPV)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_file = \"%s%s_%s_ER_fp.npy\" % (out_metric_dir, pdb_id, pfam_id)\n",
    "tp_file = \"%s%s_%s_MF_tp.npy\" % (out_metric_dir, pdb_id, pfam_id)\n",
    "np.save(fp_file, fpr0_ER)\n",
    "np.save(tp_file, tpr0_ER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc89f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89212449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
